{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c037640-8343-454f-8e78-098a553aff0a",
   "metadata": {},
   "source": [
    "# Modeling with Keras\n",
    "\n",
    "In this notebook, I will try to use Tensorflow to build a Neural Network that performs better than the GLM results.\n",
    "                                                                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f618df3-4972-4047-9c19-daed7507a8a5",
   "metadata": {},
   "source": [
    "# Todo\n",
    "\n",
    "Section 3.2 - Load data as dataset type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47442d84-f9f6-4403-b0d2-f210bf0e1103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from tensorflow.data.experimental import make_csv_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1458f9a-0e32-4545-800d-df22bfdd6787",
   "metadata": {},
   "source": [
    "# Loading\n",
    "\n",
    "## As pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c69511d8-57fe-4c67-9053-46cf80c25dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInput = pd.read_csv('../output/dataReady.csv', index_col = 'idx')\n",
    "dfInput.quality = pd.Categorical(dfInput.quality)\n",
    "dfInput.quality = dfInput.quality.cat.codes\n",
    "\n",
    "columns = [column for column in dfInput.columns if column not in ['Set','citric acid', 'free sulfur dioxide']]\n",
    "\n",
    "dfTrain = dfInput.loc[dfInput.Set == 'train', columns]\n",
    "dfVal = dfInput.loc[dfInput.Set == 'valid', columns]\n",
    "dfTest = dfInput.loc[dfInput.Set == 'test', columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "178ac934-a3ff-400d-a8e7-7b2638d9b8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.660</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>5.4</td>\n",
       "      <td>0.740</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.089</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.99402</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>11.6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.620</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.068</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99651</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1107 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  residual sugar  chlorides  \\\n",
       "idx                                                                \n",
       "0               7.4             0.700             1.9      0.076   \n",
       "1               7.8             0.880             2.6      0.098   \n",
       "2               7.8             0.760             2.3      0.092   \n",
       "3              11.2             0.280             1.9      0.075   \n",
       "5               7.4             0.660             1.8      0.075   \n",
       "...             ...               ...             ...        ...   \n",
       "1591            5.4             0.740             1.7      0.089   \n",
       "1593            6.8             0.620             1.9      0.068   \n",
       "1595            5.9             0.550             2.2      0.062   \n",
       "1596            6.3             0.510             2.3      0.076   \n",
       "1597            5.9             0.645             2.0      0.075   \n",
       "\n",
       "      total sulfur dioxide  density    pH  sulphates  alcohol  quality  \n",
       "idx                                                                     \n",
       "0                     34.0  0.99780  3.51       0.56      9.4        2  \n",
       "1                     67.0  0.99680  3.20       0.68      9.8        2  \n",
       "2                     54.0  0.99700  3.26       0.65      9.8        2  \n",
       "3                     60.0  0.99800  3.16       0.58      9.8        3  \n",
       "5                     40.0  0.99780  3.51       0.56      9.4        2  \n",
       "...                    ...      ...   ...        ...      ...      ...  \n",
       "1591                  26.0  0.99402  3.67       0.56     11.6        3  \n",
       "1593                  38.0  0.99651  3.42       0.82      9.5        3  \n",
       "1595                  51.0  0.99512  3.52       0.76     11.2        3  \n",
       "1596                  40.0  0.99574  3.42       0.75     11.0        3  \n",
       "1597                  44.0  0.99547  3.57       0.71     10.2        2  \n",
       "\n",
       "[1107 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff3d21-b48a-43e0-9495-d677b03627c7",
   "metadata": {},
   "source": [
    "## As tf data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e23ee9b-6e77-4bf0-9253-84aab52d6b03",
   "metadata": {},
   "source": [
    "I want to practice with objects of the type https://www.tensorflow.org/guide/data, to be as analogous to `PyTorch` `Dataloader` as possible.  \n",
    "https://www.tensorflow.org/api_docs/python/tf/data/experimental/make_csv_dataset  \n",
    "https://www.tensorflow.org/tutorials/load_data/csv#using_tfdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f0ad14d-1ad1-4935-886b-81bb64173607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tensorTrain = make_csv_dataset('../output/dataReady.csv',\\n                              label_name = 'quality',\\n                              batch_size = 512,\\n                              select_columns = columns)\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"tensorTrain = make_csv_dataset('../output/dataReady.csv',\n",
    "                              label_name = 'quality',\n",
    "                              batch_size = 512,\n",
    "                              select_columns = columns)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54455b7d-3948-4302-8099-a0f3cf9d02e8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "But I'm still not able to do it. I'm not sure if this is the right code, but I'll revise it in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b4cf3-278d-440b-a157-e5b81dd17f75",
   "metadata": {},
   "source": [
    "# Building a Keras Model\n",
    "\n",
    "\n",
    "## First Architecture\n",
    "\n",
    "Lets remember that GLM results showed a score of 63% accuracy. Lets try to beat that with a simple neural network.  \n",
    "I will also take the results taken from analysing the features in the first notebook. That means I will first remove the features `citric acid` and `free sulfur dioxide`.  This step was already done in section 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "641f8e21-f797-4040-89df-3e16f2776983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(dfTrain.quality.to_numpy().astype(str))\n",
    "predictors = dfTrain[[column for column in dfTrain.columns if column != 'quality']]\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "val_pred_x = dfVal[[column for column in dfVal.columns if column != 'quality']]\n",
    "val_pred_y = dfVal['quality']\n",
    "val_data = (val_pred_x.to_numpy(), to_categorical(val_pred_y))\n",
    "test_pred = dfTest[[column for column in dfTest.columns if column != 'quality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "733af5b6-d289-4145-9187-367116abb1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1107, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8070bd7c-2c6a-450c-a94a-924c20c67764",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed9e5457-bf62-4d72-be3a-21be3471b7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 [==============================] - 1s 21ms/step - loss: 1.7345 - accuracy: 0.4065 - val_loss: 3.8923 - val_accuracy: 0.4133\n",
      "Epoch 2/10000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.2942 - accuracy: 0.4860 - val_loss: 3.3721 - val_accuracy: 0.3933\n",
      "Epoch 3/10000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.1365 - accuracy: 0.5429 - val_loss: 2.6850 - val_accuracy: 0.3800\n",
      "Epoch 4/10000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0309 - accuracy: 0.5664 - val_loss: 2.2064 - val_accuracy: 0.3933\n",
      "Epoch 5/10000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9945 - accuracy: 0.5917 - val_loss: 1.8626 - val_accuracy: 0.3733\n",
      "Epoch 6/10000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9747 - accuracy: 0.6007 - val_loss: 1.6635 - val_accuracy: 0.3533\n",
      "Epoch 7/10000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9541 - accuracy: 0.6016 - val_loss: 1.5411 - val_accuracy: 0.3533\n",
      "Epoch 8/10000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9342 - accuracy: 0.6161 - val_loss: 1.4429 - val_accuracy: 0.4000\n",
      "Epoch 9/10000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9288 - accuracy: 0.6188 - val_loss: 1.3586 - val_accuracy: 0.4267\n",
      "Epoch 10/10000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9153 - accuracy: 0.6224 - val_loss: 1.3455 - val_accuracy: 0.4000\n",
      "Epoch 11/10000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9077 - accuracy: 0.6269 - val_loss: 1.3001 - val_accuracy: 0.4533\n",
      "Epoch 12/10000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8983 - accuracy: 0.6323 - val_loss: 1.2916 - val_accuracy: 0.4533\n",
      "Epoch 13/10000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8821 - accuracy: 0.6341 - val_loss: 1.2668 - val_accuracy: 0.4867\n",
      "Epoch 14/10000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8720 - accuracy: 0.6423 - val_loss: 1.2434 - val_accuracy: 0.5200\n",
      "Epoch 15/10000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8779 - accuracy: 0.6369 - val_loss: 1.2429 - val_accuracy: 0.5200\n",
      "Epoch 16/10000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8636 - accuracy: 0.6396 - val_loss: 1.2174 - val_accuracy: 0.5133\n",
      "Epoch 17/10000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8578 - accuracy: 0.6414 - val_loss: 1.1775 - val_accuracy: 0.5067\n",
      "Epoch 18/10000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8512 - accuracy: 0.6369 - val_loss: 1.1618 - val_accuracy: 0.5133\n",
      "Epoch 19/10000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8481 - accuracy: 0.6441 - val_loss: 1.1603 - val_accuracy: 0.5267\n",
      "Epoch 20/10000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8296 - accuracy: 0.6486 - val_loss: 1.1847 - val_accuracy: 0.5133\n",
      "Epoch 21/10000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8177 - accuracy: 0.6667 - val_loss: 1.1563 - val_accuracy: 0.5067\n",
      "Epoch 22/10000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8326 - accuracy: 0.6405 - val_loss: 1.1334 - val_accuracy: 0.5133\n",
      "Epoch 23/10000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8248 - accuracy: 0.6513 - val_loss: 1.1161 - val_accuracy: 0.5333\n",
      "Epoch 24/10000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.8384 - accuracy: 0.6468 - val_loss: 1.1403 - val_accuracy: 0.5000\n",
      "Epoch 25/10000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8170 - accuracy: 0.6558 - val_loss: 1.0703 - val_accuracy: 0.5333\n",
      "Epoch 26/10000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.8011 - accuracy: 0.6504 - val_loss: 1.0612 - val_accuracy: 0.5800\n",
      "Epoch 27/10000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8110 - accuracy: 0.6667 - val_loss: 1.1105 - val_accuracy: 0.5533\n",
      "Epoch 28/10000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8055 - accuracy: 0.6631 - val_loss: 1.1155 - val_accuracy: 0.5400\n",
      "Epoch 29/10000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8101 - accuracy: 0.6549 - val_loss: 1.0415 - val_accuracy: 0.5733\n",
      "Epoch 30/10000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8089 - accuracy: 0.6621 - val_loss: 1.0122 - val_accuracy: 0.5667\n",
      "Epoch 31/10000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7808 - accuracy: 0.6703 - val_loss: 0.9775 - val_accuracy: 0.6067\n",
      "Epoch 32/10000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8020 - accuracy: 0.6649 - val_loss: 0.9922 - val_accuracy: 0.6067\n",
      "Epoch 33/10000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7893 - accuracy: 0.6649 - val_loss: 1.0104 - val_accuracy: 0.6000\n",
      "Epoch 34/10000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7721 - accuracy: 0.6893 - val_loss: 0.9916 - val_accuracy: 0.6200\n",
      "Epoch 35/10000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7749 - accuracy: 0.6694 - val_loss: 0.9574 - val_accuracy: 0.6400\n",
      "Epoch 36/10000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7894 - accuracy: 0.6631 - val_loss: 0.9443 - val_accuracy: 0.6133\n",
      "Epoch 37/10000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7673 - accuracy: 0.6893 - val_loss: 0.9467 - val_accuracy: 0.6200\n",
      "Epoch 38/10000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7510 - accuracy: 0.7010 - val_loss: 0.9462 - val_accuracy: 0.5933\n",
      "Epoch 39/10000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7580 - accuracy: 0.6865 - val_loss: 0.9563 - val_accuracy: 0.6067\n",
      "Epoch 40/10000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7487 - accuracy: 0.6902 - val_loss: 0.9977 - val_accuracy: 0.5933\n",
      "Epoch 41/10000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7486 - accuracy: 0.6766 - val_loss: 0.9861 - val_accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.random import set_seed \n",
    "from keras.layers import LeakyReLU, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "callback_earlyStop = EarlyStopping(monitor = 'val_loss', patience = 5)\n",
    "\n",
    "set_seed(2)\n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "# , activation = 'tanh',\n",
    "model.add(Dense(100, input_shape=(n_cols,), activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(90, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(60, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(6, activation = 'softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = 'adam', \n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target, validation_data = val_data,  \n",
    "          epochs = 10000,\n",
    "          batch_size = 120,\n",
    "          callbacks = [callback_earlyStop])\n",
    "\n",
    "# Calculate predictions: predictions\n",
    "predictions = model.predict(test_pred)\n",
    "\n",
    "# Calculate predicted probability of survival: predicted_prob_true\n",
    "predicted_prob_true = predictions[:,1]\n",
    "\n",
    "#class_names = ['1', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "#               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "#class_names[np.argmax(predictions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc85c5a8-0df6-4af8-89dd-d0a4d1ba44cd",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n",
    "\n",
    "The first results with a deep learning network approach achieve a result of `54%`. This is much lower than the simpler, Generalized Linear Model approach. Maybe the data is more linear than expected? (https://towardsdatascience.com/comparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222). Maybe other architectures can help solve this problem more correctly?  \n",
    "Anyway, a good exercise here is to understand what is wrong with the network. For this, lets apply diagnosis methods to the results.  \n",
    "Since Neural networks are black-boxes, it's a bit more difficult to see what's happening inside them.  \n",
    "Lets see the precision and recall first, in conjuction with the confusion matrix. This will give us a notion of where the model is getting the wrong predictions.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c9524e6-4e76-40e3-96a4-2c26a3873b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.4834005e-06, 6.3279282e-10, 4.3329425e-08, ..., 3.5714686e-01,\n",
       "        5.2631233e-02, 1.8169214e-04],\n",
       "       [5.0403793e-07, 1.3289708e-11, 2.0113839e-09, ..., 3.0752793e-01,\n",
       "        3.3972379e-02, 4.7690737e-05],\n",
       "       [4.4714748e-03, 4.0964858e-04, 1.2691598e-03, ..., 3.3101794e-01,\n",
       "        1.3937207e-01, 1.9592891e-02],\n",
       "       ...,\n",
       "       [1.6748980e-03, 5.5920071e-05, 2.6740556e-04, ..., 3.9610863e-01,\n",
       "        1.1850980e-01, 1.0648130e-02],\n",
       "       [1.6470120e-09, 5.2513941e-16, 5.7090042e-13, ..., 2.2778614e-01,\n",
       "        8.2790209e-03, 1.0019511e-06],\n",
       "       [1.5414407e-04, 3.8650828e-07, 7.0067526e-06, ..., 4.5771411e-01,\n",
       "        8.9703560e-02, 1.8022447e-03]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac30cf-3835-41cf-ac61-c785697c49a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
