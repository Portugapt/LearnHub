{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11a62691-163a-4826-972e-ee47685db1ff",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "You've seen (and used) techniques to extract general insights from a machine learning model. But what if you want to break down how the model works for an individual prediction?\n",
    "\n",
    "SHAP Values (an acronym from SHapley Additive exPlanations) break down a prediction to show the impact of each feature. Where could you use this?\n",
    "\n",
    "- A model says a bank shouldn't loan someone money, and the bank is legally required to explain the basis for each loan rejection\n",
    "- A healthcare provider wants to identify what factors are driving each patient's risk of some disease so they can directly address those risk factors with targeted health interventions\n",
    "\n",
    "You'll use SHAP Values to explain individual predictions in this lesson. In the next lesson, you'll see how these can be aggregated into powerful model-level insights.\n",
    "\n",
    "# How They Work\n",
    "SHAP values interpret the impact of having a certain value for a given feature in comparison to the prediction we'd make if that feature took some baseline value.\n",
    "\n",
    "An example is helpful, and we'll continue the soccer/football example from the [permutation importance](https://www.kaggle.com/dansbecker/permutation-importance) and [partial dependence plots](https://www.kaggle.com/dansbecker/partial-plots) lessons.\n",
    "\n",
    "\n",
    "In these tutorials, we predicted whether a team would have a player win the *Man of the Match* award.\n",
    "\n",
    "We could ask:\n",
    "- **How much was a prediction driven by the fact that the team scored 3 goals?**\n",
    "    \n",
    "But it's easier to give a concrete, numeric answer if we restate this as:\n",
    "- How much was a prediction driven by the fact that the team scored 3 goals, **instead of some baseline number of goals.**\n",
    "\n",
    "Of course, each team has many features. So if we answer this question for `number of goals`, we could repeat the process for all other features.\n",
    "\n",
    "SHAP values do this in a way that guarantees a nice property. Specifically, you decompose a prediction with the following equation:\n",
    "\n",
    "```sum(SHAP values for all features) = pred_for_team - pred_for_baseline_values```\n",
    "\n",
    "That is, the SHAP values of all features sum up to explain why my prediction was different from the baseline. This allows us to decompose a prediction in a graph like this:\n",
    "\n",
    "![Imgur](https://i.imgur.com/JVD2U7k.png)\n",
    "\n",
    "*If you want a larger view of this graph, [here is a link](https://i.imgur.com/JVD2U7k.png)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b03ac-bb83-4c23-b36f-86ba884b5032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
